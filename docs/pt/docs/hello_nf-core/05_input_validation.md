# Parte 5: Valida√ß√£o de entrada

<span class="ai-translation-notice">:material-information-outline:{ .ai-translation-notice-icon } Tradu√ß√£o assistida por IA - [saiba mais e sugira melhorias](https://github.com/nextflow-io/training/blob/master/TRANSLATING.md)</span>

Na quinta parte do curso de treinamento Hello nf-core, mostramos como usar o plugin nf-schema para validar entradas e par√¢metros do pipeline.

??? info "Como come√ßar a partir desta se√ß√£o"

    Esta se√ß√£o assume que voc√™ completou a [Parte 4: Criar um m√≥dulo nf-core](./04_make_module.md) e atualizou o m√≥dulo de processo `COWPY` para os padr√µes nf-core em seu pipeline.

    Se voc√™ n√£o completou a Parte 4 ou quer come√ßar do zero para esta parte, pode usar a solu√ß√£o `core-hello-part4` como ponto de partida.
    Execute estes comandos de dentro do diret√≥rio `hello-nf-core/`:

    ```bash
    cp -r solutions/core-hello-part4 core-hello
    cd core-hello
    ```

    Isso fornece um pipeline com o m√≥dulo `COWPY` j√° atualizado para seguir os padr√µes nf-core.
    Voc√™ pode testar se ele executa com sucesso executando o seguinte comando:

    ```bash
    nextflow run . --outdir core-hello-results -profile test,docker --validate_params false
    ```

---

## 0. Aquecimento: Um pouco de contexto

### 0.1. Por que a valida√ß√£o √© importante

Imagine executar seu pipeline por duas horas, apenas para ele falhar porque um usu√°rio forneceu um arquivo com a extens√£o errada. Ou passar horas depurando erros enigm√°ticos, apenas para descobrir que um par√¢metro foi escrito incorretamente. Sem valida√ß√£o de entrada, esses cen√°rios s√£o comuns.

Considere este exemplo:

```console title="Sem valida√ß√£o"
$ nextflow run my-pipeline --input data.txt --output results

...2 horas depois...

ERROR ~ No such file: 'data.fq.gz'
  Expected FASTQ format but received TXT
```

O pipeline aceitou entradas inv√°lidas e executou por horas antes de falhar. Com valida√ß√£o adequada:

```console title="Com valida√ß√£o"
$ nextflow run my-pipeline --input data.txt --output results

ERROR ~ Validation of pipeline parameters failed!

 * --input (data.txt): File extension '.txt' does not match required pattern '.fq.gz' or '.fastq.gz'
 * --output: required parameter is missing (expected: --outdir)

Pipeline failed before execution - please fix the errors above
```

O pipeline falha imediatamente com mensagens de erro claras e acion√°veis. Isso economiza tempo, recursos computacionais e frustra√ß√£o.

### 0.2. O plugin nf-schema

O [plugin nf-schema](https://nextflow-io.github.io/nf-schema/latest/) √© um plugin Nextflow que fornece capacidades abrangentes de valida√ß√£o para pipelines Nextflow.
Embora o nf-schema funcione com qualquer fluxo de trabalho Nextflow, √© a solu√ß√£o de valida√ß√£o padr√£o para todos os pipelines nf-core.

O nf-schema fornece v√°rias fun√ß√µes principais:

- **Valida√ß√£o de par√¢metros**: Valida par√¢metros do pipeline contra `nextflow_schema.json`
- **Valida√ß√£o de planilha de amostras**: Valida arquivos de entrada contra `assets/schema_input.json`
- **Convers√£o de canal**: Converte planilhas de amostras validadas em canais Nextflow
- **Gera√ß√£o de texto de ajuda**: Gera automaticamente sa√≠da `--help` a partir de defini√ß√µes de schema
- **Resumo de par√¢metros**: Exibe quais par√¢metros diferem dos padr√µes

O nf-schema √© o sucessor do plugin nf-validation descontinuado e usa o padr√£o [JSON Schema Draft 2020-12](https://json-schema.org/) para valida√ß√£o.

??? info "O que s√£o plugins Nextflow?"

    Plugins s√£o extens√µes que adicionam novas funcionalidades √† pr√≥pria linguagem Nextflow. Eles s√£o instalados via um bloco `plugins{}` em `nextflow.config` e podem fornecer:

    - Novas fun√ß√µes e classes que podem ser importadas (como `samplesheetToList`)
    - Novos recursos DSL e operadores
    - Integra√ß√£o com servi√ßos externos

    O plugin nf-schema √© especificado em `nextflow.config`:

    ```groovy
    plugins {
        id 'nf-schema@2.1.1'
    }
    ```

    Uma vez instalado, voc√™ pode importar fun√ß√µes de plugins usando a sintaxe `include { functionName } from 'plugin/plugin-name'`.

### 0.3. Dois arquivos de schema para dois tipos de valida√ß√£o

Um pipeline nf-core utilizar√° dois arquivos de schema separados, que correspondem a dois tipos de valida√ß√£o:

| Arquivo de Schema          | Prop√≥sito                     | Valida                                                      |
| -------------------------- | ----------------------------- | ----------------------------------------------------------- |
| `nextflow_schema.json`     | Valida√ß√£o de par√¢metros       | Flags de linha de comando: `--input`, `--outdir`, `--batch` |
| `assets/schema_input.json` | Valida√ß√£o de dados de entrada | Conte√∫do de planilhas de amostras e arquivos de entrada     |

Ambos os schemas usam o formato JSON Schema, um padr√£o amplamente adotado para descrever e validar estruturas de dados.

**Valida√ß√£o de par√¢metros** valida par√¢metros de linha de comando (flags como `--outdir`, `--batch`, `--input`):

- Verifica tipos, intervalos e formatos de par√¢metros
- Garante que par√¢metros obrigat√≥rios sejam fornecidos
- Valida se os caminhos de arquivo existem
- Definida em `nextflow_schema.json`

**Valida√ß√£o de dados de entrada** valida a estrutura de planilhas de amostras e arquivos de manifesto (arquivos CSV/TSV que descrevem seus dados):

- Verifica estrutura de colunas e tipos de dados
- Valida se os caminhos de arquivo referenciados na planilha de amostras existem
- Garante que campos obrigat√≥rios estejam presentes
- Definida em `assets/schema_input.json`

!!! warning "O que a valida√ß√£o de dados de entrada N√ÉO faz"

    A valida√ß√£o de dados de entrada verifica a estrutura de *arquivos de manifesto* (planilhas de amostras, arquivos CSV), N√ÉO o conte√∫do dos seus arquivos de dados reais (FASTQ, BAM, VCF, etc.).

    Para dados em larga escala, validar o conte√∫do dos arquivos (como verificar a integridade de BAM) deve acontecer em processos do pipeline executando em n√≥s de trabalho, n√£o durante a etapa de valida√ß√£o na m√°quina de orquestra√ß√£o.

### 0.4. Quando a valida√ß√£o deve ocorrer?

```mermaid
graph LR
    A[Usu√°rio executa o pipeline] --> B[Valida√ß√£o de par√¢metros]
    B -->|‚úì V√°lido| C[Valida√ß√£o de dados de entrada]
    B -->|‚úó Inv√°lido| D[Erro: Corrigir par√¢metros]
    C -->|‚úì V√°lido| E[Pipeline executa]
    C -->|‚úó Inv√°lido| F[Erro: Corrigir dados de entrada]
```

A valida√ß√£o deve acontecer **antes** de qualquer processo do pipeline executar, para fornecer feedback r√°pido e evitar tempo de computa√ß√£o desperdi√ßado.

Agora vamos aplicar esses princ√≠pios na pr√°tica, come√ßando com a valida√ß√£o de par√¢metros.

---

## 1. Valida√ß√£o de par√¢metros (nextflow_schema.json)

Vamos come√ßar adicionando valida√ß√£o de par√¢metros ao nosso pipeline. Isso valida flags de linha de comando como `--input`, `--outdir` e `--batch`.

### 1.1. Configurar a valida√ß√£o para ignorar valida√ß√£o de arquivo de entrada

O template de pipeline nf-core vem com o nf-schema j√° instalado e configurado:

- O plugin nf-schema √© instalado via o bloco `plugins{}` em `nextflow.config`
- A valida√ß√£o de par√¢metros √© habilitada por padr√£o via `params.validate_params = true`
- A valida√ß√£o √© realizada pelo subworkflow `UTILS_NFSCHEMA_PLUGIN` durante a inicializa√ß√£o do pipeline

O comportamento de valida√ß√£o √© controlado atrav√©s do escopo `validation{}` em `nextflow.config`.

Como estaremos trabalhando na valida√ß√£o de par√¢metros primeiro (esta se√ß√£o) e n√£o configuraremos o schema de dados de entrada at√© a se√ß√£o 2, precisamos temporariamente dizer ao nf-schema para ignorar a valida√ß√£o do conte√∫do do arquivo do par√¢metro `input`.

Abra `nextflow.config` e encontre o bloco `validation` (por volta da linha 246). Adicione `ignoreParams` para ignorar a valida√ß√£o de arquivo de entrada:

=== "Depois"

    ```groovy title="nextflow.config" hl_lines="3" linenums="246"
    validation {
        defaultIgnoreParams = ["genomes"]
        ignoreParams = ['input']
        monochromeLogs = params.monochrome_logs
    }
    ```

=== "Antes"

    ```groovy title="nextflow.config" linenums="246"
    validation {
        defaultIgnoreParams = ["genomes"]
        monochromeLogs = params.monochrome_logs
    }
    ```

Esta configura√ß√£o diz ao nf-schema para:

- **`defaultIgnoreParams`**: Ignorar valida√ß√£o de par√¢metros complexos como `genomes` (definido pelos desenvolvedores do template)
- **`ignoreParams`**: Ignorar valida√ß√£o do conte√∫do do arquivo do par√¢metro `input` (tempor√°rio; vamos reabilitar isso na se√ß√£o 2)
- **`monochromeLogs`**: Desabilitar sa√≠da colorida em mensagens de valida√ß√£o quando definido como `true` (controlado por `params.monochrome_logs`)

!!! note "Por que ignorar o par√¢metro input?"

    O par√¢metro `input` em `nextflow_schema.json` tem `"schema": "assets/schema_input.json"` que diz ao nf-schema para validar o *conte√∫do* do arquivo CSV de entrada contra esse schema.
    Como ainda n√£o configuramos esse schema, temporariamente ignoramos essa valida√ß√£o.
    Removeremos essa configura√ß√£o na se√ß√£o 2 ap√≥s configurar o schema de dados de entrada.

### 1.2. Examinar o schema de par√¢metros

Vamos olhar uma se√ß√£o do arquivo `nextflow_schema.json` que veio com nosso template de pipeline:

```bash
grep -A 25 '"input_output_options"' nextflow_schema.json
```

O schema de par√¢metros √© organizado em grupos. Aqui est√° o grupo `input_output_options`:

```json title="core-hello/nextflow_schema.json (trecho)" linenums="8"
        "input_output_options": {
            "title": "Input/output options",
            "type": "object",
            "fa_icon": "fas fa-terminal",
            "description": "Define where the pipeline should find input data and save output data.",
            "required": ["input", "outdir"],
            "properties": {
                "input": {
                    "type": "string",
                    "format": "file-path",
                    "exists": true,
                    "schema": "assets/schema_input.json",
                    "mimetype": "text/csv",
                    "pattern": "^\\S+\\.csv$",
                    "description": "Path to comma-separated file containing information about the samples in the experiment.",
                    "help_text": "You will need to create a design file with information about the samples in your experiment before running the pipeline. Use this parameter to specify its location. It has to be a comma-separated file with 3 columns, and a header row.",
                    "fa_icon": "fas fa-file-csv"
                },
                "outdir": {
                    "type": "string",
                    "format": "directory-path",
                    "description": "The output directory where the results will be saved. You have to use absolute paths to storage on Cloud infrastructure.",
                    "fa_icon": "fas fa-folder-open"
                }
            }
        },
```

Cada entrada descrita aqui tem as seguintes propriedades principais que podem ser validadas:

- **`type`**: Tipo de dado (string, integer, boolean, number)
- **`format`**: Formatos especiais como `file-path` ou `directory-path`
- **`exists`**: Para caminhos de arquivo, verifica se o arquivo existe
- **`pattern`**: Express√£o regular que o valor deve corresponder
- **`required`**: Array de nomes de par√¢metros que devem ser fornecidos
- **`mimetype`**: Mimetype de arquivo esperado para valida√ß√£o

Se voc√™ tem olhar afiado, pode perceber que o par√¢metro de entrada `batch` que temos usado ainda n√£o est√° definido no schema.
Vamos adicion√°-lo na pr√≥xima se√ß√£o.

??? info "De onde v√™m os par√¢metros do schema?"

    A valida√ß√£o do schema usa `nextflow.config` como base para defini√ß√µes de par√¢metros.
    Par√¢metros declarados em outros lugares nos seus scripts de fluxo de trabalho (como em `main.nf` ou arquivos de m√≥dulo) **n√£o** s√£o automaticamente capturados pelo validador de schema.

    Isso significa que voc√™ deve sempre declarar seus par√¢metros de pipeline em `nextflow.config`, e ent√£o definir suas regras de valida√ß√£o em `nextflow_schema.json`.

### 1.3. Adicionar o par√¢metro batch

Embora o schema seja um arquivo JSON que possa ser editado manualmente, **a edi√ß√£o manual √© propensa a erros e n√£o √© recomendada**.
Em vez disso, o nf-core fornece uma ferramenta GUI interativa que manipula a sintaxe JSON Schema para voc√™ e valida suas altera√ß√µes:

```bash
nf-core pipelines schema build
```

Voc√™ deve ver algo assim:

```console
                                      ,--./,-.
      ___     __   __   __   ___     /,-._.--\
|\ | |__  __ /  ` /  \ |__) |__         }  {
| \| |       \__, \__/ |  \ |___     \`-._,-`-,
                                      `._,._,'

nf-core/tools version 3.4.1 - https://nf-co.re

INFO     [‚úì] Default parameters match schema validation
INFO     [‚úì] Pipeline schema looks valid (found 17 params)
INFO     Writing schema with 17 params: 'nextflow_schema.json'
üöÄ  Launch web builder for customisation and editing? [y/n]:
```

Digite `y` e pressione Enter para iniciar a interface web interativa.

Seu navegador abrir√° mostrando o construtor de schema de par√¢metros:

![Interface do construtor de schema](./img/schema_build.png)

Para adicionar o par√¢metro `batch`:

1. Clique no bot√£o **"Add parameter"** no topo
2. Use a al√ßa de arrastar (‚ãÆ‚ãÆ) para mover o novo par√¢metro para cima no grupo "Input/output options", abaixo do par√¢metro `input`
3. Preencha os detalhes do par√¢metro:
   - **ID**: `batch`
   - **Description**: `Name for this batch of greetings`
   - **Type**: `string`
   - **Required**: marque a caixa de sele√ß√£o
   - Opcionalmente, selecione um √≠cone do seletor de √≠cones (ex: `fas fa-layer-group`)

![Adicionando o par√¢metro batch](./img/schema_add.png)

Quando terminar, clique no bot√£o **"Finished"** no canto superior direito.

De volta ao seu terminal, voc√™ ver√°:

```console
INFO     Writing schema with 18 params: 'nextflow_schema.json'
‚£æ Use ctrl+c to stop waiting and force exit.
```

Pressione `Ctrl+C` para sair do construtor de schema.

A ferramenta agora atualizou seu arquivo `nextflow_schema.json` com o novo par√¢metro `batch`, manipulando toda a sintaxe JSON Schema corretamente.

### 1.4. Verificar as altera√ß√µes

```bash
grep -A 25 '"input_output_options"' nextflow_schema.json
```

```json title="core-hello/nextflow_schema.json (trecho)" linenums="8" hl_lines="19-23"
    "input_output_options": {
      "title": "Input/output options",
      "type": "object",
      "fa_icon": "fas fa-terminal",
      "description": "Define where the pipeline should find input data and save output data.",
      "required": ["input", "outdir", "batch"],
      "properties": {
        "input": {
          "type": "string",
          "format": "file-path",
          "exists": true,
          "schema": "assets/schema_input.json",
          "mimetype": "text/csv",
          "pattern": "^\\S+\\.csv$",
          "description": "Path to comma-separated file containing information about the samples in the experiment.",
          "help_text": "You will need to create a design file with information about the samples in your experiment before running the pipeline. Use this parameter to specify its location. It has to be a comma-separated file with 3 columns, and a header row.",
          "fa_icon": "fas fa-file-csv"
        },
        "batch": {
          "type": "string",
          "description": "Name for this batch of greetings",
          "fa_icon": "fas fa-layer-group"
        },
```

Voc√™ deve ver que o par√¢metro `batch` foi adicionado ao schema com o campo "required" agora mostrando `["input", "outdir", "batch"]`.

### 1.5. Testar a valida√ß√£o de par√¢metros

Agora vamos testar que a valida√ß√£o de par√¢metros funciona corretamente.

Primeiro, tente executar sem o par√¢metro obrigat√≥rio `input`:

```bash
nextflow run . --outdir test-results -profile docker
```

??? warning "Sa√≠da do comando"

    ```console
    ERROR ~ Validation of pipeline parameters failed!

    -- Check '.nextflow.log' file for details
    The following invalid input values have been detected:

    * Missing required parameter(s): input, batch
    ```

Perfeito! A valida√ß√£o captura o par√¢metro obrigat√≥rio faltante antes do pipeline executar.

Agora tente com um conjunto v√°lido de par√¢metros:

```bash
nextflow run . --input assets/greetings.csv --outdir results --batch my-batch -profile test,docker
```

??? success "Sa√≠da do comando"

    ```console
     N E X T F L O W   ~  version 25.04.3

    Launching `./main.nf` [peaceful_wozniak] DSL2 - revision: b9e9b3b8de

    executor >  local (8)
    [de/a1b2c3] CORE_HELLO:HELLO:sayHello (3)       | 3 of 3 ‚úî
    [4f/d5e6f7] CORE_HELLO:HELLO:convertToUpper (3) | 3 of 3 ‚úî
    [8a/b9c0d1] CORE_HELLO:HELLO:CAT_CAT (test)     | 1 of 1 ‚úî
    [e2/f3a4b5] CORE_HELLO:HELLO:COWPY (test)       | 1 of 1 ‚úî
    -[core/hello] Pipeline completed successfully-
    ```

O pipeline deve executar com sucesso, e o par√¢metro `batch` agora est√° validado.

### Conclus√£o

Voc√™ aprendeu como usar a ferramenta interativa `nf-core pipelines schema build` para adicionar par√¢metros ao `nextflow_schema.json` e viu a valida√ß√£o de par√¢metros em a√ß√£o.
A interface web manipula toda a sintaxe JSON Schema para voc√™, facilitando o gerenciamento de schemas de par√¢metros complexos sem edi√ß√£o JSON manual propensa a erros.

### Pr√≥ximos passos

Agora que a valida√ß√£o de par√¢metros est√° funcionando, vamos adicionar valida√ß√£o para o conte√∫do do arquivo de dados de entrada.

---

## 2. Valida√ß√£o de dados de entrada (schema_input.json)

Vamos adicionar valida√ß√£o para o conte√∫do do nosso arquivo CSV de entrada.
Enquanto a valida√ß√£o de par√¢metros verifica flags de linha de comando, a valida√ß√£o de dados de entrada garante que os dados dentro do arquivo CSV estejam estruturados corretamente.

### 2.1. Entender o formato greetings.csv

Vamos relembrar como nossa entrada se parece:

```bash
cat assets/greetings.csv
```

```csv title="assets/greetings.csv"
Hello,en,87
Bonjour,fr,96
Hol√†,es,98
```

Este √© um CSV simples com:

- Tr√™s colunas (sem cabe√ßalho)
- Em cada linha: uma sauda√ß√£o, um idioma e uma pontua√ß√£o
- As duas primeiras colunas s√£o strings de texto sem requisitos de formato especiais
- A terceira coluna √© um inteiro

Para nosso pipeline, apenas a primeira coluna √© obrigat√≥ria.

### 2.2. Projetar a estrutura do schema

Para nosso caso de uso, queremos:

1. Aceitar entrada CSV com pelo menos uma coluna
2. Tratar o primeiro elemento de cada linha como uma string de sauda√ß√£o
3. Garantir que as sauda√ß√µes n√£o estejam vazias e n√£o comecem com espa√ßo em branco
4. Garantir que o campo de idioma corresponda a um dos c√≥digos de idioma suportados (en, fr, es, it, de)
5. Garantir que o campo de pontua√ß√£o seja um inteiro com valor entre 0 e 100

Vamos estruturar isso como um array de objetos, onde cada objeto tem pelo menos um campo `greeting`.

### 2.3. Atualizar o arquivo de schema

O template de pipeline nf-core inclui um `assets/schema_input.json` padr√£o projetado para dados de sequenciamento paired-end.
Precisamos substitu√≠-lo por um schema mais simples para nosso caso de uso de sauda√ß√µes.

Abra `assets/schema_input.json` e substitua as se√ß√µes `properties` e `required`:

=== "Depois"

    ```json title="assets/schema_input.json" linenums="1" hl_lines="10-25 27"
    {
        "$schema": "https://json-schema.org/draft/2020-12/schema",
        "$id": "https://raw.githubusercontent.com/core/hello/main/assets/schema_input.json",
        "title": "core/hello pipeline - params.input schema",
        "description": "Schema for the greetings file provided with params.input",
        "type": "array",
        "items": {
            "type": "object",
            "properties": {
                "greeting": {
                    "type": "string",
                    "pattern": "^\\S.*$",
                    "errorMessage": "Greeting must be provided and cannot be empty or start with whitespace"
                },
                "language": {
                    "type": "string",
                    "enum": ["en", "fr", "es", "it", "de"],
                    "errorMessage": "Language must be one of: en, fr, es, it, de"
                },
                "score": {
                    "type": "integer",
                    "minimum": 0,
                    "maximum": 100,
                    "errorMessage": "Score must be an integer with a value between 0 and 100"
                }
            },
            "required": ["greeting"]
        }
    }
    ```

=== "Antes"

    ```json title="assets/schema_input.json" linenums="1" hl_lines="10-29 31"
    {
        "$schema": "https://json-schema.org/draft/2020-12/schema",
        "$id": "https://raw.githubusercontent.com/core/hello/main/assets/schema_input.json",
        "title": "core/hello pipeline - params.input schema",
        "description": "Schema for the file provided with params.input",
        "type": "array",
        "items": {
            "type": "object",
            "properties": {
                "sample": {
                    "type": "string",
                    "pattern": "^\\S+$",
                    "errorMessage": "Sample name must be provided and cannot contain spaces",
                    "meta": ["id"]
                },
                "fastq_1": {
                    "type": "string",
                    "format": "file-path",
                    "exists": true,
                    "pattern": "^([\\S\\s]*\\/)?[^\\s\\/]+\\.f(ast)?q\\.gz$",
                    "errorMessage": "FastQ file for reads 1 must be provided, cannot contain spaces and must have extension '.fq.gz' or '.fastq.gz'"
                },
                "fastq_2": {
                    "type": "string",
                    "format": "file-path",
                    "exists": true,
                    "pattern": "^([\\S\\s]*\\/)?[^\\s\\/]+\\.f(ast)?q\\.gz$",
                    "errorMessage": "FastQ file for reads 2 cannot contain spaces and must have extension '.fq.gz' or '.fastq.gz'"
                }
            },
            "required": ["sample", "fastq_1"]
        }
    }
    ```

As principais mudan√ßas:

- **`description`**: Atualizada para mencionar "greetings file"
- **`properties`**: Substitu√≠das `sample`, `fastq_1` e `fastq_2` por `greeting`, `language` e `score`
  - **`type:`** Imp√µe string (`greeting`, `language`) ou integer (`score`)
  - **`pattern: "^\\S.*$"`**: A sauda√ß√£o deve come√ßar com um caractere que n√£o seja espa√ßo em branco (mas pode conter espa√ßos depois disso)
  - **`"enum": ["en", "fr", "es", "it", "de"]`**: O c√≥digo de idioma deve estar no conjunto suportado
  - **`"minimum": 0` e `"maximum": 100`**: O valor da pontua√ß√£o deve estar entre 0 e 100
  - **`errorMessage`**: Mensagem de erro personalizada mostrada se a valida√ß√£o falhar
- **`required`**: Alterado de `["sample", "fastq_1"]` para `["greeting"]`

### 2.4. Adicionar um cabe√ßalho ao arquivo greetings.csv

Quando o nf-schema l√™ um arquivo CSV, ele espera que a primeira linha contenha cabe√ßalhos de colunas que correspondam aos nomes de campos no schema.

Para nosso caso simples, precisamos adicionar uma linha de cabe√ßalho ao nosso arquivo de sauda√ß√µes:

=== "Depois"

    ```csv title="assets/greetings.csv" linenums="1" hl_lines="1"
    greeting,language,score
    Hello,en,87
    Bonjour,fr,96
    Hol√†,es,98
    ```

=== "Antes"

    ```csv title="assets/greetings.csv" linenums="1"
    Hello,en,87
    Bonjour,fr,96
    Hol√†,es,98
    ```

Agora o arquivo CSV tem uma linha de cabe√ßalho que corresponde aos nomes de campos em nosso schema.

O passo final √© implementar a valida√ß√£o no c√≥digo do pipeline usando `samplesheetToList`.

### 2.5. Implementar valida√ß√£o no pipeline

Agora precisamos substituir nossa an√°lise CSV simples pela fun√ß√£o `samplesheetToList` do nf-schema, que validar√° e analisar√° a planilha de amostras.

A fun√ß√£o `samplesheetToList`:

1. L√™ a planilha de amostras de entrada (CSV, TSV, JSON ou YAML)
2. Valida contra o schema JSON fornecido
3. Retorna uma lista Groovy onde cada entrada corresponde a uma linha
4. Lan√ßa mensagens de erro √∫teis se a valida√ß√£o falhar

Vamos atualizar o c√≥digo de manipula√ß√£o de entrada:

Abra `subworkflows/local/utils_nfcore_hello_pipeline/main.nf` e localize a se√ß√£o onde criamos o canal de entrada (por volta da linha 80).

Precisamos:

1. Usar a fun√ß√£o `samplesheetToList` (j√° importada no template)
2. Validar e analisar a entrada
3. Extrair apenas as strings de sauda√ß√£o para nosso fluxo de trabalho

Primeiro, note que a fun√ß√£o `samplesheetToList` j√° est√° importada no topo do arquivo (o template nf-core inclui isso por padr√£o):

```groovy title="core-hello/subworkflows/local/utils_nfcore_hello_pipeline/main.nf" linenums="1" hl_lines="13"
//
// Subfluxo de trabalho com funcionalidade espec√≠fica para o pipeline core/hello
//

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    IMPORT FUNCTIONS / MODULES / SUBWORKFLOWS
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

include { UTILS_NFSCHEMA_PLUGIN     } from '../../nf-core/utils_nfschema_plugin'
include { paramsSummaryMap          } from 'plugin/nf-schema'
include { samplesheetToList         } from 'plugin/nf-schema'
include { paramsHelp                } from 'plugin/nf-schema'
include { completionSummary         } from '../../nf-core/utils_nfcore_pipeline'
include { UTILS_NFCORE_PIPELINE     } from '../../nf-core/utils_nfcore_pipeline'
include { UTILS_NEXTFLOW_PIPELINE   } from '../../nf-core/utils_nextflow_pipeline'
```

Agora atualize o c√≥digo de cria√ß√£o do canal:

=== "Depois"

    ```groovy title="core-hello/subworkflows/local/utils_nfcore_hello_pipeline/main.nf" linenums="80" hl_lines="4"
        //
        // Cria canal a partir do arquivo de entrada fornecido atrav√©s de params.input
        //
        ch_samplesheet = channel.fromList(samplesheetToList(params.input, "${projectDir}/assets/schema_input.json"))
            .map { line -> line[0] }

        emit:
        samplesheet = ch_samplesheet
        versions    = ch_versions
    ```

=== "Antes"

    ```groovy title="core-hello/subworkflows/local/utils_nfcore_hello_pipeline/main.nf" linenums="80" hl_lines="4 5"
        //
        // Cria canal a partir do arquivo de entrada fornecido atrav√©s de params.input
        //
        ch_samplesheet = channel.fromPath(params.input)
            .splitCsv()
            .map { line -> line[0] }

        emit:
        samplesheet = ch_samplesheet
        versions    = ch_versions
    ```

Vamos detalhar o que mudou:

1. **`samplesheetToList(params.input, "${projectDir}/assets/schema_input.json")`**: Valida o arquivo de entrada contra nosso schema e retorna uma lista
2. **`Channel.fromList(...)`**: Converte a lista em um canal Nextflow

Isso completa a implementa√ß√£o da valida√ß√£o de dados de entrada usando `samplesheetToList` e schemas JSON.

Agora que configuramos o schema de dados de entrada, podemos remover a configura√ß√£o de ignorar tempor√°ria que adicionamos anteriormente.

### 2.6. Reabilitar valida√ß√£o de entrada

Abra `nextflow.config` e remova a linha `ignoreParams` do bloco `validation`:

=== "Depois"

    ```groovy title="nextflow.config" linenums="246"
    validation {
        defaultIgnoreParams = ["genomes"]
        monochromeLogs = params.monochrome_logs
    }
    ```

=== "Antes"

    ```groovy title="nextflow.config" hl_lines="3" linenums="246"
    validation {
        defaultIgnoreParams = ["genomes"]
        ignoreParams = ['input']
        monochromeLogs = params.monochrome_logs
    }
    ```

Agora o nf-schema validar√° tanto os tipos de par√¢metros QUANTO o conte√∫do do arquivo de entrada.

### 2.7. Testar valida√ß√£o de entrada

Vamos verificar que nossa valida√ß√£o funciona testando entradas v√°lidas e inv√°lidas.

#### 2.7.1. Testar com entrada v√°lida

Primeiro, confirme que o pipeline executa com sucesso com entrada v√°lida.
Note que n√£o precisamos mais de `--validate_params false` j√° que a valida√ß√£o est√° funcionando!

```bash
nextflow run . --outdir core-hello-results -profile test,docker
```

??? success "Sa√≠da do comando"

    ```console
    ------------------------------------------------------
    WARN: The following invalid input values have been detected:

    * --character: tux


    executor >  local (8)
    [c1/39f64a] CORE_HELLO:HELLO:sayHello (1)       | 3 of 3 ‚úî
    [44/c3fb82] CORE_HELLO:HELLO:convertToUpper (3) | 3 of 3 ‚úî
    [62/80fab2] CORE_HELLO:HELLO:CAT_CAT (test)     | 1 of 1 ‚úî
    [e1/4db4fd] CORE_HELLO:HELLO:COWPY (test)       | 1 of 1 ‚úî
    -[core/hello] Pipeline completed successfully-
    ```

√ìtimo! O pipeline executa com sucesso e a valida√ß√£o passa silenciosamente.
O aviso sobre `--character` √© apenas informativo j√° que n√£o est√° definido no schema.
Se quiser, use o que aprendeu para adicionar valida√ß√£o para esse par√¢metro tamb√©m!

#### 2.7.2. Testar com entrada inv√°lida

Passar na valida√ß√£o √© sempre uma boa sensa√ß√£o, mas vamos garantir que a valida√ß√£o realmente capturar√° erros.

Para criar um arquivo de teste com um nome de coluna inv√°lido, comece fazendo uma c√≥pia do arquivo `greetings.csv`:

```bash
cp assets/greetings.csv assets/invalid_greetings.csv
```

Agora abra o arquivo e mude o nome da primeira coluna, na linha de cabe√ßalho, de `greeting` para `message`:

=== "Depois"

    ```csv title="tmp_invalid_greetings.csv" hl_lines="1" linenums="1"
    message,language,score
    Hello,en,87
    Bonjour,fr,96
    Hol√†,es,98
    ```

=== "Antes"

    ```csv title="tmp_invalid_greetings.csv" hl_lines="1" linenums="1"
    greeting,language,score
    Hello,en,87
    Bonjour,fr,96
    Hol√†,es,98
    ```

Isso n√£o corresponde ao nosso schema, ent√£o a valida√ß√£o deve lan√ßar um erro.

Tente executar o pipeline com esta entrada inv√°lida:

```bash
nextflow run . --input assets/invalid_greetings.csv --outdir test-results -profile docker
```

??? failure "Sa√≠da do comando"

    ```console
    N E X T F L O W   ~  version 24.10.4

    Launching `./main.nf` [trusting_ochoa] DSL2 - revision: b9e9b3b8de

    Input/output options
      input              : assets/invalid_greetings.csv
      outdir             : test-results

    Generic options
      trace_report_suffix: 2025-01-27_03-16-04

    Core Nextflow options
      runName            : trusting_ochoa
      containerEngine    : docker
      launchDir          : /workspace/hello-nf-core
      workDir            : /workspace/hello-nf-core/work
      projectDir         : /workspace/hello-nf-core
      userName           : user
      profile            : docker
      configFiles        : /workspace/hello-nf-core/nextflow.config

    !! Only displaying parameters that differ from the pipeline defaults !!
    ------------------------------------------------------
    ERROR ~ Validation of pipeline parameters failed!

     -- Check '.nextflow.log' file for details
    The following invalid input values have been detected:

    * Missing required parameter(s): batch
    * --input (assets/invalid_greetings.csv): Validation of file failed:
        -> Entry 1: Missing required field(s): greeting
        -> Entry 2: Missing required field(s): greeting
        -> Entry 3: Missing required field(s): greeting

     -- Check script 'subworkflows/nf-core/utils_nfschema_plugin/main.nf' at line: 68 or see '.nextflow.log' file for more details
    ```

Perfeito! A valida√ß√£o capturou o erro e forneceu uma mensagem de erro clara e √∫til apontando para:

- Qual arquivo falhou na valida√ß√£o
- Qual entrada (linha 1, a primeira linha de dados) tem o problema
- Qual √© o problema espec√≠fico (campo obrigat√≥rio `greeting` ausente)

A valida√ß√£o do schema garante que os arquivos de entrada tenham a estrutura correta antes do pipeline executar, economizando tempo e prevenindo erros confusos mais tarde na execu√ß√£o.

Se quiser praticar isso, sinta-se livre para criar outros arquivos de entrada de sauda√ß√µes que violem o schema de outras maneiras divertidas.

### Conclus√£o

Voc√™ implementou e testou tanto a valida√ß√£o de par√¢metros quanto a valida√ß√£o de dados de entrada. Seu pipeline agora valida entradas antes da execu√ß√£o, fornecendo feedback r√°pido e mensagens de erro claras.

!!! tip "Leitura adicional"

    Para aprender mais sobre recursos e padr√µes avan√ßados de valida√ß√£o, consulte a [documenta√ß√£o do nf-schema](https://nextflow-io.github.io/nf-schema/latest/). O comando `nf-core pipelines schema build` fornece uma GUI interativa para gerenciar schemas complexos.

### Pr√≥ximos passos

Voc√™ completou todas as cinco partes do curso de treinamento Hello nf-core!

Continue para o [Resumo](summary.md) para refletir sobre o que voc√™ construiu e aprendeu.
